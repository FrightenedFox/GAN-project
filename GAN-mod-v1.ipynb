{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e598af-53e0-4ba4-8a4f-d493d6b81bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6baa3e3-b91c-40cb-a7a0-e0020f98a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 2    # number of epochs of training\n",
    "BATCH_SIZE = 50   # size of the batches\n",
    "LR = 5e-5         # adam: learning rate\n",
    "B1 = 0.5          # adam: decay of first order momentum of gradient\n",
    "B2 = 0.999        # adam: decay of first order momentum of gradient\n",
    "\n",
    "N_CPU = 11         # number of cpu threads to use during batch generation\n",
    "LATENT_DIM = 100  # dimensionality of the latent space\n",
    "IMG_SIZE = 28     # size of each image dimension\n",
    "CHANNELS = 1      # number of image channels\n",
    "SAMPLE_INTERVAL = 400 # interval betwen image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b382d675-d0ec-4717-8120-cba1ec9501e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: False\n"
     ]
    }
   ],
   "source": [
    "img_shape = (CHANNELS, IMG_SIZE, IMG_SIZE)\n",
    "torch.manual_seed(12345)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "print(\"CUDA:\", cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31eea90a-bf82-4375-a575-3b5064d57b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(LATENT_DIM, 7 * 7 * 64)\n",
    "        \n",
    "        # initializing weights (maybe biases will be added later as well)\n",
    "        self.scaled_mats = torch.rand(2, 7 * 7, 4, 4, requires_grad=True)\n",
    "        self.imag_weights = torch.rand(64 * 2, requires_grad=True)\n",
    "        \n",
    "#         def block(in_feat, out_feat, normalize=True):\n",
    "#             layers = [nn.Linear(in_feat, out_feat)]\n",
    "#             if normalize:\n",
    "#                 layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "#             layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "#             return layers\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             *block(LATENT_DIM, 128, normalize=False),\n",
    "#             *block(128, 256),\n",
    "#             *block(256, 512),\n",
    "#             *block(512, 1024),\n",
    "#             nn.Linear(1024, int(np.prod(img_shape))),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "    def forward(self, z):\n",
    "        flat_z = F.relu(self.fc1(z))\n",
    "        small_imgs = flat_z.view(flat_z.size(0), 64, 7, 7)\n",
    "        \n",
    "        # multiplying each element of the small_imgs with the corresponding matrix \n",
    "        # in the self.scaled_mats\n",
    "        big_imgs = F.relu(torch.stack([\n",
    "            torch.stack([\n",
    "                torch.cat([\n",
    "                    torch.cat([\n",
    "                        (small_imgs[batch][layer % 64][row][col] * \n",
    "                         self.scaled_mats[layer % 2][(row + 1) * (col + 1) - 1])\n",
    "                        for col in range(7)\n",
    "                    ], dim=1)\n",
    "                    for row in range(7)\n",
    "                ], dim=0)\n",
    "                for layer in range(64 * 2)\n",
    "            ])\n",
    "            for batch in range(BATCH_SIZE)\n",
    "        ]))\n",
    "        \n",
    "        weighted_img = torch.stack([\n",
    "            torch.sum(big_imgs[batch] * self.imag_weights.view(128, 1, 1), dim=0)\n",
    "            for batch in range(BATCH_SIZE)\n",
    "        ])\n",
    "\n",
    "        return weighted_img.view(weighted_img.size(0), *img_shape)\n",
    "#         img = self.model(z)\n",
    "#         img = img.view(img.size(0), *img_shape)\n",
    "#         return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42418403-6cb9-494a-9548-cfb3115b1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "#         print(\"validity:\\n\", validity)\n",
    "#         print(validity.shape)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca719bfb-8a77-4b8e-8cad-7c90a7034abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26c3a47-2160-41e4-90a1-d92f604a3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "# os.makedirs(\"../PyTorch/MNIST\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(IMG_SIZE), \n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize([0.5], [0.5])\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992f65c0-ec9d-4f6f-a0e5-fc288f477797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=LR, betas=(B1, B2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=LR, betas=(B1, B2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20796dc5-15ce-47c3-adb4-ec676f7979eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_imgs:  torch.Size([50, 1, 28, 28])\n",
      "scaled_mats:  torch.Size([2, 49, 4, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))))\n",
    "\n",
    "generator = Generator()\n",
    "gen_imgs = generator(z)\n",
    "plt.imshow(gen_imgs[0][0].detach().numpy())\n",
    "print(\"gen_imgs: \", gen_imgs.size())\n",
    "print(\"scaled_mats: \", generator.scaled_mats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86a4f7-459b-4063-b56d-4c123907712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    print(len(dataloader))\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        print(i)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], LATENT_DIM))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % SAMPLE_INTERVAL == 0:\n",
    "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "        \n",
    "        if i == 100:\n",
    "            break \n",
    "    print(\n",
    "            \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, N_EPOCHS, d_loss.item(), g_loss.item())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d685122d-3f2b-48cb-b652-ab6d4c167ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ff713-b648-430d-ab30-ed4d5366e452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
