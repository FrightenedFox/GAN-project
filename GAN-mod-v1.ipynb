{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e598af-53e0-4ba4-8a4f-d493d6b81bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6baa3e3-b91c-40cb-a7a0-e0020f98a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 2    # number of epochs of training\n",
    "BATCH_SIZE = 50   # size of the batches\n",
    "LR = 1e-5         # adam: learning rate\n",
    "B1 = 0.5          # adam: decay of first order momentum of gradient\n",
    "B2 = 0.999        # adam: decay of first order momentum of gradient\n",
    "\n",
    "N_CPU = 11         # number of cpu threads to use during batch generation\n",
    "LATENT_DIM = 100  # dimensionality of the latent space\n",
    "IMG_SIZE = 28     # size of each image dimension\n",
    "CHANNELS = 1      # number of image channels\n",
    "SAMPLE_INTERVAL = 100 # interval betwen image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b382d675-d0ec-4717-8120-cba1ec9501e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: False\n"
     ]
    }
   ],
   "source": [
    "img_shape = (CHANNELS, IMG_SIZE, IMG_SIZE)\n",
    "torch.manual_seed(12345)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "print(\"CUDA:\", cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "31eea90a-bf82-4375-a575-3b5064d57b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(LATENT_DIM, 128)\n",
    "        self.fc2 = nn.Linear(128, 7 * 7 * 64)\n",
    "        \n",
    "        # initializing weights (maybe biases will be added later as well)\n",
    "        self.scaled_mats = torch.normal(0, 1, size=(2, 7, 7, 4, 4), requires_grad=True)\n",
    "        self.scaled_mats = self.scaled_mats.view(1, 2, 7, 7, 4, 4)\n",
    "        self.scaled_mats = torch.repeat_interleave(self.scaled_mats, 64, dim=1)\n",
    "        \n",
    "        self.scaled_mats_bias = torch.normal(0, 1, size=(2, 7, 7, 4, 4), requires_grad=True)\n",
    "        self.scaled_mats_bias = self.scaled_mats_bias.view(1, 2, 7, 7, 4, 4)\n",
    "        self.scaled_mats_bias = torch.repeat_interleave(self.scaled_mats_bias, 64, dim=1)\n",
    "        \n",
    "        self.imag_weights = torch.normal(0, 1, size=(64 * 2, 1), requires_grad=True).view(1, 128, 1, 1)\n",
    "        \n",
    "        self.imag_weights_bias = torch.normal(0, 1, size=(64 * 2, 1), requires_grad=True).view(1, 128, 1, 1)\n",
    "        \n",
    "    def tt(self, m, n, i, j):\n",
    "        t1 = torch.arange(0, m * n, i * j).view(int(m / i), int(n / j)).repeat_interleave(i, dim=0).repeat_interleave(j, dim=1)\n",
    "        t2 = torch.arange(i * j).view(i, j).repeat(int(m / i), int(n / j))\n",
    "        return (t1 + t2).view(m * n)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \n",
    "        flat_z = F.leaky_relu(self.fc1(z))\n",
    "        flat_z = F.leaky_relu(self.fc2(flat_z))\n",
    "        \n",
    "        small_imgs = flat_z.view(flat_z.size(0), 64, 7, 7, 1, 1)\n",
    "        small_imgs = small_imgs.repeat(1, 2, 1, 1, 1, 1)\n",
    "        \n",
    "        big_imgs = torch.mul(self.scaled_mats, small_imgs)\n",
    "        big_imgs = torch.add(self.scaled_mats_bias, big_imgs)\n",
    "        big_imgs = big_imgs.view(BATCH_SIZE, 128, 7 * 4 * 7 * 4).transpose(0, -1)\n",
    "        big_imgs = big_imgs[self.tt(28, 28, 4, 4)].transpose(0, -1)\n",
    "        big_imgs = F.leaky_relu(big_imgs.view(BATCH_SIZE, 128, 7 * 4, 7 * 4))\n",
    "        \n",
    "        weighted_img = torch.add(torch.mul(big_imgs, self.imag_weights), self.imag_weights_bias)\n",
    "#         weighted_img = F.softmax(torch.sum(weighted_img, dim=1))\n",
    "        weighted_img = torch.tanh(torch.sum(weighted_img, dim=1))\n",
    "\n",
    "        return weighted_img.view(weighted_img.size(0), *img_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "42418403-6cb9-494a-9548-cfb3115b1a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "#         print(\"validity:\\n\", validity)\n",
    "#         print(validity.shape)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ca719bfb-8a77-4b8e-8cad-7c90a7034abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f26c3a47-2160-41e4-90a1-d92f604a3938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "# os.makedirs(\"../PyTorch/MNIST\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(IMG_SIZE), \n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize([0.5], [0.5])\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "992f65c0-ec9d-4f6f-a0e5-fc288f477797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=LR, betas=(B1, B2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=LR, betas=(B1, B2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "20796dc5-15ce-47c3-adb4-ec676f7979eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_imgs:  torch.Size([50, 1, 28, 28])\n",
      "scaled_mats:  torch.Size([1, 128, 7, 7, 4, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))))\n",
    "\n",
    "generator = Generator()\n",
    "gen_imgs = generator(z)\n",
    "plt.imshow(gen_imgs[0][0].detach().numpy())\n",
    "print(\"gen_imgs: \", gen_imgs.size())\n",
    "print(\"scaled_mats: \", generator.scaled_mats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ab86a4f7-459b-4063-b56d-4c123907712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 0/2400] [D loss: 0.731780] [G loss: 0.645129]\n",
      "[Batch 100/2400] [D loss: 0.164634] [G loss: 2.115231]\n",
      "[Batch 200/2400] [D loss: 0.040977] [G loss: 3.462831]\n",
      "[Batch 300/2400] [D loss: 0.017040] [G loss: 4.363126]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-e9b586fdf6f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PyTorch-Jupyter\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PyTorch-Jupyter\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], LATENT_DIM))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % SAMPLE_INTERVAL == 0:\n",
    "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "            print(\n",
    "                \"[Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (batches_done, len(dataloader)*N_EPOCHS, d_loss.item(), g_loss.item())\n",
    "            ) \n",
    "    print(\n",
    "            \"--- [Epoch %d/%d] [D loss: %f] [G loss: %f] ---\"\n",
    "            % (epoch, N_EPOCHS, d_loss.item(), g_loss.item())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685122d-3f2b-48cb-b652-ab6d4c167ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ff713-b648-430d-ab30-ed4d5366e452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
